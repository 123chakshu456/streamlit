{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-7e767c4f-a4bd-463c-b10b-1081a0ae595a",
        "deepnote_cell_type": "code"
      },
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-0655caef-2402-46fc-a4c7-15e0b45116bf",
        "deepnote_cell_type": "code"
      },
      "source": "from gevent import monkey as curious_george\ncurious_george.patch_all(thread=False, select=False)\nimport sys\nimport requests\nimport grequests\nimport pandas as pd\nimport numpy as np\nimport re\nfrom bs4 import BeautifulSoup\nimport time\nimport matplotlib.pyplot as plt\nimport sweetviz as sv\nfrom matplotlib import cm\nimport seaborn as sns\nimport scipy.stats as st\nimport statsmodels as sm\nfrom scipy.stats import pearsonr\nimport chart_studio.plotly as py\nimport plotly.graph_objects as go\n\nimport plotly.express as px\n\ndef scraper(base_url):\n    base_url = \"https://www.goodreads.com/list/show/264.Books_That_Everyone_Should_Read_At_Least_Once?page={}\"\n\n\ndef get_pages_links(string, index):\n    links = []\n    for index in range(1,index):\n        url = string.format(index)\n        links.append(url)\n    return links\n    \ndef grequest_page(strings, index):\n    reqs = (grequests.get(string) for string in strings)\n    resp = grequests.imap(reqs, grequests.Pool(index))\n    return resp\ndef request_single_page(string):\n    res = requests.get(string)\n    return res\n\ndef request_soup(page):\n    soup = BeautifulSoup(page.content ,\"html.parser\")\n    return soup\n\ndef close_request(request_page):\n    request_page.close()\n    return\n\ndef read_books_links(page_soup):\n    Links = []\n    #table = page_soup.find_all('table', class_ = 'tableList js-dataTooltip')\n    #print(table)\n    books = page_soup.find_all('tr')\n    for book in books:\n        info_book = book.find('a', class_ = 'bookTitle')\n        book_link = \"https://www.goodreads.com{}\".format(info_book['href'])\n        Links.append(book_link)    \n    return Links\ndef get_bookslink(index):\n    Links_res = []\n    page = grequest_page(get_pages_links(base_url, index), index)\n    for r in page: \n        soup = request_soup(r)\n        Links_res = Links_res + read_books_links(soup)\n    print(len(Links_res))\n    with open(\"Links_for_each_book.txt\", \"w\") as output:\n        output.write(str(Links_res))\n    return Links_res\n\ndef get_pubDate(data):  \n    if data.find('nobr', class_ = \"greyText\") is not None:\n        firstPub = data.find('nobr', class_ = \"greyText\").text\n        firstPub = firstPub.strip()\n        firstPub = firstPub[-5:]\n        firstPub = firstPub.replace(\")\",\"\")\n        return firstPub\n    else: return np.nan\n\ndef get_genres(book):\n    genres = []\n    names = book.find_all('a', class_=\"actionLinkLite bookPageGenreLink\")\n    if names is not None:\n        for name in names:\n          genres.append(name.get_text())  \n        return genres\n    else:\n        return np.nan\n\ndef get_awards(book):\n    awards_list = []    \n    names = book.find_all('a', class_=\"award\")\n    if names is not None:\n        for name in names:\n            awards_list.append(name.get_text())\n        return awards_list\n    else: \n        return np.nan\n    \ndef get_places(book):\n    return\n\ndef get_info_book(page_soup, link, index):\n    book = page_soup.find_all('div', class_ = 'mainContentFloat')\n    for data in book:\n        #TITLE of the Book\n        title = data.find('h1')\n        if title is not None:\n            title = title.text\n            title = title.strip()\n        else: title = np.nan\n        #AUTHOR of the book\n        author = data.find('a', class_ = \"authorName\")\n        if author is not None:\n            author = author.text\n        else: author = np.nan\n        #RATING COUNT of the book\n        ratingCount = data.find('meta', itemprop = \"ratingCount\")\n        if ratingCount is not None:\n            ratingCount = ratingCount.text\n            ratingCount = re.sub(\"\\D\", \"\", ratingCount)\n        else: ratingCount = np.nan\n        #REVIEW COUNT of the book\n        reviewCount = data.find('meta', itemprop = \"reviewCount\")\n        if reviewCount is not None:\n            reviewCount = reviewCount.text\n            reviewCount = re.sub(\"\\D\", \"\", reviewCount)\n        else: reviewCount = np.nan\n        #RATING VALUE of the book\n        ratingValue = data.find('span', itemprop = \"ratingValue\")\n        if ratingValue is not None:\n            ratingValue = ratingValue.text\n            ratingValue = ratingValue.strip()\n        else: ratingValue = np.nan\n        #NUMBER OF PAGES of the book\n        numberOfPages = data.find('span', itemprop = \"numberOfPages\")\n        if numberOfPages is not None:\n            numberOfPages = numberOfPages.text\n            numberOfPages = re.sub(\"\\D\", \"\", numberOfPages)\n        else: numberOfPages = np.nan\n        #YEAR OF FIRST PUBBLICATION of the book\n        firstPub = get_pubDate(data)\n        #CHECK IF IT IS A SERIES OR NOT\n        series = data.find('div', id = \"bookDataBox\").text\n        if \"Series\" in series: \n            series = '1'\n        else: \n            series = '0'\n        #GENRES of the book\n        genreList = get_genres(data)\n        #AWARDS of the book\n        awards = get_awards(data)\n        #PLACES of the book\n \n        \n        #Return Dictionary\n        Book_dict = {\n                \"Link\":link,\n                \"Title\":title,\n                \"Author\":author,\n                \"Rating Count\":ratingCount,\n                \"Review Count\":reviewCount,\n                \"Rating Value\":ratingValue,\n                \"N pag\":numberOfPages,\n                \"1st Pub\":firstPub,\n                \"series\":series,\n                \"Genres\":genreList,\n                \"Awards\":awards}\n        #print(index,\"  \",link,\"\\n__\",title,author,ratingCount, reviewCount, ratingValue, numberOfPages,firstPub,           series, genreList, awards,\"\\n\\n\")\n        return Book_dict\n\n\n\ndef create_csv(index):\n    links = get_bookslink(index + 1)\n    res_dict = {}\n    i = 1\n    page = grequest_page(links, index + 1)\n    df = pd.DataFrame()\n    for r, link in zip(page, links): \n        soup = request_soup(r)\n        value = get_info_book(soup, link, i)\n        if value is not None:\n            df = df.append(value, ignore_index=True)\n        i = i + 1\n        print(df.tail())\n    df.to_csv('./Books_total.csv')\n    return\n    def preprocessing (csv):\n    \n    data = pd.read_csv(csv)\n    \n    cols = ['Unnamed: 0','Link','Title','Author','Review Count','Rating Count','Rating Value','1st Pub','series','Genres','Awards','N pag']\n\n    df = data[cols]\n    df.rename(columns={'Unnamed: 0':\"unnamed_0\",'Link':\"url\",'Title':\"title\",'Author':\"author\",\n    'Review Count':\"num_reviews\",'Rating Count':\"num_ratings\",\n    'Rating Value':\"avg_ratings\",'1st Pub':\"original_publish_year\",'series':\"series\",\n    'Genres':\"genres\",'Awards':\"awards\",'N pag':\"num_pages\"},inplace=True)\n    df.drop(['unnamed_0'],axis=1)\n\n    #number of awards\n    awards_number = [len(awards.split(',')) for awards in df['awards'] ]\n    df[\"award_number\"]= awards_number\n\n    #normalizations\n    maxr=df['avg_ratings'].max()\n    minr =df['avg_ratings'].min()\n    meanr= df['avg_ratings'].mean()\n    #mean_normalization\n    df['mean_norm_ratings'] = round(((df['avg_ratings']- meanr) / (maxr- minr)),2)\n\n    #min-max normalization\n    df['min_max'] = round((1 + ((df.avg_ratings-minr)/(maxr-minr))*9),2)\n    \n    #cleaning\n    df=df.fillna(0)\n    df.num_pages = df.num_pages.astype(float).astype(int)\n    df.original_publish_year = df.original_publish_year.astype(float).astype(int)\n    df.series = df.series.astype(bool)\n\n    df =df.drop('unnamed_0',axis=1)\n    \n    #for streamlit\n    df.to_csv('Books_universe.csv')\n\n\n    return df\n\ndef anaylse(df):\n\n    def eda():\n        df.describe()\n        df.info()\n    eda()\n\n\n    # Statistics:\n    def correlation():\n        corr = df.corr()\n\n        mask = np.triu(np.ones_like(corr, dtype=bool))\n        cmap = sns.diverging_palette(230, 20, as_cmap=True)\n        sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n                    square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    correlation()\n\n    #Displot\n    def displots():\n\n        sns.displot(df['min_max'], bins= 20, edgecolor= \"white\", kde= True, alpha= 0.5)\n\n        sns.displot(df['mean_norm_ratings'], bins= 20, edgecolor= \"white\",kde= True, alpha= 0.65, color= '#008367')\n         plt.xlabel(\"mean_norm_rating distribution\")\n    displots()\n\n    def distributions():\n        #4min max rating distribution\n        plt.rcParams.update({'figure.figsize':(7,5)})\n        #plt.hist(df.min_max, bins= 20) #we could change the bins\n        sns.displot(df['min_max'], bins= 20, edgecolor= \"white\", kde= True, alpha= 0.75)\n\n        plt.rcParams.update({'figure.figsize':(7,5)})\n        plt.hist(df['min_max'], alpha=0.5, label='Min-Max', edgecolor= \"w\")\n        plt.hist(df['mean_norm_ratings'], alpha=0.5, label='Mean_Norm', edgecolor= \"w\")\n        plt.legend(loc='upper right')\n        plt.show()\n\n    \n    def outlier():\n        fig = px.box(df['award_number'],title=\"Visualizing the Outliers for No. of Awards \")\n        fig.show()\n    outlier()\n\n    def graphs():\n    # Checking data\n    \n    #anlysis by author \n    #Average Ratings vs Number of Ratings\n\n        dx=df.sort_values(by=('min_max'), ascending= False)[0:200]\n        dx\n        fig = px.scatter(dx, x=dx[\"min_max\"].values, y=dx[\"num_ratings\"], hover_name=dx[\"title\"],size=dx['num_pages']*10000, \n        hover_data=['num_pages','author'],labels={\n                            \"x\":\"Average Ratings\",\n                            \"y\":\"Number of Ratings\",\n                            \n                        },color=dx[\"author\"])\n\n        #fig.update_traces(marker=dict(size=df['num_pages']/15))\n        fig.update_xaxes(showgrid=False)\n        fig.update_yaxes(showgrid=False )\n        fig.update(layout_showlegend=False)\n        fig.update_layout(plot_bgcolor=\"black\", height= 600,width=1000,title_text='Number of Ratings in comparison to the Number of Ratings')\n        fig.show()\n\n        #Another one\n        authors = df.groupby(['author'])['award_number'].count()\n        authors =pd.DataFrame(authors)\n        authors = authors.sort_values(by=['award_number'],ascending=False)[0:50]\n        fig = px.bar(authors, x=authors.index.values, y=authors.award_number,color_continuous_scale='agsunset',\n        labels={\n                            \"x\":\"Authors\",\n                            \"y\":\"Award Count\"\n                            \n                        }\n                        )\n\n        fig.update_traces(marker=dict(size=12,\n                                    line=dict(width=1\n                                                )),\n                        selector=dict(mode='markers'))\n        fig.update_xaxes(showgrid=False)\n        fig.update_yaxes(showgrid=False )\n        fig.update(layout_showlegend=False)\n\n        fig.update_layout(plot_bgcolor=\"black\",\n        height=800,width=800,\n        title_text='Number of Awards Won by an Individual Author(Top 50 Authors)'\n        )\n\n        fig.show()\n\n        #Another one\n        authors_ratings = df.groupby(['author'])['min_max'].mean()\n        authors_ratings =pd.DataFrame(authors_ratings).sort_values(by=['min_max'],ascending=False)[0:50]\n        fig = px.scatter(authors_ratings, x=authors_ratings.index.values, y=authors_ratings.min_max,\n        labels={\n                            \"x\":\"Authors\",\n                            \"y\":\"Average Rating\",\n                            \n                        },color=authors_ratings.index\n                        )\n\n        fig.update_traces(marker=dict(size=12,\n                                    line=dict(width=1,\n                                                )),\n                        selector=dict(mode='markers'))\n        fig.update_xaxes(showgrid=False)\n        fig.update_yaxes(showgrid=False )\n        fig.update(layout_showlegend=False)\n        fig.update_layout(plot_bgcolor=\"black\",\n        height=800,\n        title_text='Average Rating per Author in the DataFrame'\n        )\n\n        fig.show()\n\nif __name__ == \"__main__\":    \n    create_csv(1)\n    print(\"--- %s seconds ---\" % (time.time() - start_time))",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-c0a5f495-aeee-4746-aaeb-e6d6e44387f0",
        "deepnote_cell_type": "code"
      },
      "source": "\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00003-3b904b51-47e4-446e-a5e8-d649b17102f9",
        "deepnote_cell_type": "code"
      },
      "source": "\n\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-a45fcfe9-e984-47df-8315-4bb9e5a74c33",
        "deepnote_cell_type": "code"
      },
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b8d5d41e-3ba7-4959-ae1c-b25e3642b110' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "dce34af1-4859-4bfb-9663-503d4136c86d",
    "deepnote_execution_queue": []
  }
}